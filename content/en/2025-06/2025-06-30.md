---
linkTitle: 06-30-Daily
title: 06-30-Daily AI News Daily
weight: 1
breadcrumbs: false
comments: true
description: HoPE (Hybrid of Position Embedding) is a game-changing new technique!
  Introduced by the CMU and Xiaohongshu teams, HoPE tackles the "struggle" ğŸ¤” of existing
  ...
---
## AI Insights Daily 2025/6/30

> `AI Daily Digest` ğŸ¤– | `Daily 8 AM Updates` â° | `Aggregated Web Data` ğŸ“Š | `Cutting-Edge Science Exploration` ğŸ”¬ | `Industry Voices` ğŸ—£ï¸ | `Open Source Innovation` âœ¨ | `AI & Humanity's Future` ğŸš€ | [Access Web Version](https://ai.hubtoday.app/)

### AI Content Summary

```
CMU and others introduce HoPE to enhance VLM long-video understanding; Renmin University and others optimize multimodal models with MokA.
Open-source projects include generative AI tutorials and AI tool libraries. Gary Marcus questions whether pure LLMs can achieve AGI.
AI significantly lowers startup barriers, prompts changes in investment thinking, and encourages embracing collaboration to seize opportunities.
```

### Cutting-Edge AI Research

1.  **HoPE (Hybrid of Position Embedding)** is a game-changing new technique! Introduced by the **CMU** and **Xiaohongshu** teams, HoPE tackles the "struggle" ğŸ¤” of existing `Multimodal RoPE` when handling `long-context semantic modeling`. This clever approach brings in `zero-frequency temporal modeling` and `dynamic scaling` strategies, basically fitting `Visual Language Models (VLMs)` with "marathon running shoes" ğŸ‘Ÿ! It massively boosts their `length generalization` capabilities for `long video understanding` and `retrieval` tasks, pushing them straight to peak performance ğŸ”¥. So cool! [Paper](https://arxiv.org/pdf/2505.20444) [Project](https://github.com/hrlics/HoPE)

2.  **MokA (Multimodal low-rank Adaptation)** is a stunning new breakthrough! Brought to us by the **Renmin University of China** and **Shanghai AI Lab** teams, MokA addresses a common headache in fine-tuning `Multimodal Large Language Models (MLLMs)`: the tricky balance between `single-modality independent modeling` and `inter-modal interaction`. MokA acts like a master balancer âš–ï¸, cleverly combining `modality-specific A matrices`, `cross-modal attention mechanisms`, and `shared B matrices`. This completely solves the problem, making `multimodal task` performance skyrocket ğŸš€! Amazing! [Paper](https://arxiv.org/abs/2506.05191) [More Details](https://gewu-lab.github.io/MokA)

### Top Open-Source Projects

1.  The **"generative-ai-for-beginners" project** (boasting 86,547 stars) has dropped 21 lessons specifically designed for rookies! It's a hands-on guide to mastering `generative AI` building skills. Wanna become an AI wizard ğŸ§™â€â™‚ï¸? Go check it out! [Project](https://github.com/microsoft/generative-ai-for-beginners)

2.  The **"system-prompts-and-models-of-ai-tools" project** (racking up 62,777 stars) is seriously a treasure trove ğŸ’! It gathers `system prompts`, `tools`, and `AI models` from hot `AI tools` and agents like Cursor and Devin. This project gives you a one-stop, comprehensive reference to help you master AI tools ğŸ› ï¸. [Project](https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools)

3.  The **"storm" project** (already sitting at 24,892 stars) is super impressive â›ˆï¸! This `LLM-driven knowledge management system` acts like a mini-researcher, autonomously digging into specific topics and then generating full reports with `citations`. It's a total godsend âœ¨ for writing papers or doing research! [Project](https://github.com/stanford-oval/storm)

### Social Media Buzz

1.  **Gary Marcus**, the renowned AI scholar, is back at it, stirring the pot ğŸ—£ï¸! Citing papers from `MIT`, `University of Chicago`, and `Harvard`, he bluntly states that `pure LLMs` simply cannot create `Artificial General Intelligence (AGI)` ğŸ¤¯! Why? Because they suffer from "Potemkin understanding" (fake understanding) and `conceptual inconsistency`. Basically, AI might crush it on tests, but when it comes to truly understanding and applying concepts, it totally fumbles. Research even shows that when `LLMs` like `GPT-4o` apply well-defined concepts to real-world tasks like `classification`, `generation`, or `editing`, their performance plummets ğŸ“‰. They even have `conflicting representations` internally for the same idea. This has grabbed the attention of industry bigwigs like `Google DeepMind scientist Prateek Jain`, sparking widespread interest and testing! Looks like the road to AGI is still a long one ğŸ›£ï¸ for AI! [More Details](https://www.jiqizhixin.com/articles/2025-06-29-5)
    <br/> ![LLM Conceptual Inconsistency Analysis](https://raw.githubusercontent.com/justlovemaki/imagehub/refs/heads/main/images/2025/07/news_01k023ft58f0jrbmtq7ds7pt4p.avif) <br/>

2.  **Tom Huang** has spilled the beans on the efficiency secrets ğŸ’¡ of `Cursor`'s core developers! Want to get more out of Cursor? They're teaching you how to use "Parallel Agents"! By cleverly combining `Tab`, `Formed Tab`, and `Background Agent`, you can build a super-efficient `task execution system` that will boost your `AI collaboration` big time ğŸš€! Go check out how it works ğŸ‘‹! [More Details](https://x.com/tuturetom/status/1939321864200888536)
    <br/> ![Cursor Parallel Agents Workflow](https://raw.githubusercontent.com/justlovemaki/imagehub/refs/heads/main/images/2025/07/news_01k023fww3eytsgg6jf3mg3es5.avif) <br/>

3.  **Yang Yi** has thrown out a thought-provoking idea ğŸ¤”: the content creation space is currently in an "attention arbitrage window" ğŸ’¸! He suggests that some folks are already using `AI` to "build `content leverage`," hinting that as AI becomes widespread, `human-original content` will become increasingly valuable, even commanding a premium. But what worries him even more is that `AI` could gradually "erode `human spiritual culture`" at extremely low costs â€” and that's way scarier ğŸ˜± than just a shift in content creation methods! Deep thoughts... ğŸ§  [More Details](https://x.com/Yangyixxxx/status/1939318396111430096)

4.  **Yang Yi** believes that in the `AI era`, the `startup` barrier has essentially been "slashed" ğŸ¤¯ by AI! The cost of building an `MVP (Minimum Viable Product)` has dropped significantly ğŸ’°, making `rapid idea validation` totally doable ğŸš€. His advice for entrepreneurs is: stop overthinking your ideas' viability! Just use `AI` to validate an `MVP` in as little as three days, or even quickly test 30 ideas within three months! This way, you'll find the truly worthwhile direction ğŸ”¥ to pour your heart into much faster! [More Details](https://x.com/Yangyixxxx/status/1939278373978857614)

5.  As an `AI investor`, **Yang Yi** shared his "secret weapon" ğŸ¤« for evaluating `AI startups`: he doesn't focus on hard data, but rather on `qualitative metrics`! He believes there are five key points ğŸ¯ to determine an `AI startup`'s investment value: the founder's grand vision for the future (including `PMF` and `scalability`), the team's unwavering conviction, how much `efficiency AI` has boosted ğŸš€ within team management, whether the `Agent` has a complete `feedback loop` (this is the `methodology` for `AI success`!), and the `scalability` of the `multi-agent framework`. He figures `user retention` and similar data are just "byproducts" that naturally appear over time! What a unique perspective âœ¨! [More Details](https://x.com/Yangyixxxx/status/1939212085185093664)

6.  A **user** has spilled the beans on a "new trick" ğŸ¤¯ for `coding collaboration` with `AI`ğŸ‘¨â€ğŸ’», and this mode is seriously gaining traction! Instead of rushing to give `AI detailed instructions`, you first clearly lay out the `project background` and `goals`. Then, let `AI` generate ideas based on that info, and you align on the `granularity` together through discussion. This method cleverly leverages `AI`'s efficiency in quickly understanding context, making up for our "brain cell deficiency" ğŸ§  when doing detailed planning. It massively boosts `workflow efficiency` ğŸš€ in a `collaborative mode`! It's a total godsend for programmers! [More Details](https://x.com/wwwgoubuli/status/1939168328070603017)

7.  A **user** gripes ğŸ¤¦â€â™‚ï¸ that some `investors` are still using outdated `mobile internet metrics` ğŸ•°ï¸ to evaluate `AI projects`, and the result is â€” they can't find good ones! That's because `traditional logic` (formal, informal, even `probability theory`) is all about looking back at the past. The author emphasizes that `Bayes' Theorem` is the true forward-looking `decision-making method` ğŸš€, much better suited for making investment judgments in the `AI industry`! Time to update that investment "operating system" ğŸ’¡! [More Details](https://m.okjike.com/originalPosts/6860acdfd82bae994ab2ac0e)
    <br/> ![New Investment Evaluation Perspective](https://cdnv2.ruguoapp.com/FkJ8CttPht-FSudcqveStLiBY6BBv3.png) <br/>
    <br/> ![Bayes' Theorem for AI Investment](https://cdnv2.ruguoapp.com/FhaVZhhtXfzamqX8c4dNBF62yfZRv3.png) <br/>

8.  **Dash and his colleague** bluntly state that the emergence of `AI` has essentially "flattened the playing field" ğŸ for all of humanity! They believe the massive opportunities `AI` brings even surpass the `internet wave` ğŸŒŠ of 20 years ago, allowing everyone, including entry-level employees, to break free from `resource limitations` and fully leverage `AI` to learn and create. But they also warn that if programmers remain complacent and don't push forward, that "starting line" will eventually catch up to them, even leaving them behind! So, actively embracing `AI` is the way to go ğŸ’ª!

---

## Listen to the AI Daily Digest (Audio Version)

| ğŸ™ï¸ **Xiaoyuzhou** | ğŸ“¹ **Douyin** |
| --- | --- |
| [Laisheng Xiaojiuguan](https://www.xiaoyuzhoufm.com/podcast/683c62b7c1ca9cf575a5030e) | [Self-media Account](https://www.douyin.com/user/MS4wLjABAAAAwpwqPQlu38sO38VyWgw9ZjDEnN4bMR5j8x111UxpseHR9DpB6-CveI5KRXOWuFwG) |
| ![Xiaojiuguan](https://raw.githubusercontent.com/justlovemaki/imagehub/refs/heads/main/logo/f959f7984e9163fc50d3941d79a7f262.md.png) | ![Intelligence Hub](https://raw.githubusercontent.com/justlovemaki/imagehub/refs/heads/main/logo/7fc30805eeb831e1e2baa3a240683ca3.md.png) |